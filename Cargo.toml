[package]
name = "rurel"
version = "0.5.1"
authors = ["Milan Boers <mail@milanboers.nl>"]
description = "Flexible, reusable reinforcement learning (Q learning) implementation"
documentation = "https://docs.rs/rurel"
homepage = "https://github.com/milanboers/rurel"
repository = "https://github.com/milanboers/rurel"
readme = "README.md"
keywords = ["reinforcement", "q", "learning", "dqn"]
categories = ["science", "algorithms"]
license = "MPL-2.0"
edition = "2021"

[badges]
travis-ci = { repository = "milanboers/rurel", branch = "master" }

[features]
default = []
dqn = ["dfdx"]
save = ["dfdx/safetensors", "safetensors"]
cuda = ["dfdx/cuda"]

[dependencies]
rand = "0.8"
dfdx = { version = "0.13.0", optional = true }
safetensors = { version = "0.3.3", optional = true }

[[example]]
name = "eucdist"
path = "src/examples/eucdist.rs"


[[example]]
name = "weightedcoin"
path = "src/examples/weightedcoin.rs"

[[example]]
name = "eucdist_dqn"
path = "src/examples/eucdist_dqn.rs"

[[example]]
name = "chess"
path = "src/examples/chess.rs"

[dev-dependencies]
clap = { version = "4.5.4", features = ["derive"] }
indicatif = "0.17.8"
shakmaty = "0.26.0"
